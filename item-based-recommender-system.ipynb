{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run this program\n",
    "First, please make sure that you have **python3** installed (preferably **Anaconda** package).\n",
    "\n",
    "Then use **jupyter notebook** to run the **.ipynb** file.\n",
    "\n",
    "If you have any missing python modules, please install them using **pip install**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "Load the MovieLens data (educational version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 68.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_path = \"ml-latest-small/ratings.csv\"\n",
    "data = pd.read_csv(data_path, sep=',', header=0)\n",
    "data = data[['userId', 'movieId', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data[:495]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 671\n",
      "Number of movies: 9066\n"
     ]
    }
   ],
   "source": [
    "user_ids = sorted(set(data['userId']))\n",
    "movie_ids = sorted(set(data['movieId']))\n",
    "n_users = len(user_ids)\n",
    "n_movies = len(movie_ids)\n",
    "\n",
    "print(\"Number of users: {}\\nNumber of movies: {}\".format(n_users, n_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId\n",
      "356       341\n",
      "296       324\n",
      "318       311\n",
      "593       304\n",
      "260       291\n",
      "480       274\n",
      "2571      259\n",
      "1         247\n",
      "527       244\n",
      "589       237\n",
      "1196      234\n",
      "110       228\n",
      "1270      226\n",
      "608       224\n",
      "1198      220\n",
      "2858      220\n",
      "780       218\n",
      "1210      217\n",
      "588       215\n",
      "457       213\n",
      "2959      202\n",
      "590       202\n",
      "47        201\n",
      "50        201\n",
      "4993      200\n",
      "858       200\n",
      "364       200\n",
      "150       200\n",
      "380       198\n",
      "32        196\n",
      "         ... \n",
      "26694       1\n",
      "26695       1\n",
      "26701       1\n",
      "3003        1\n",
      "26492       1\n",
      "26346       1\n",
      "3021        1\n",
      "26349       1\n",
      "26350       1\n",
      "26371       1\n",
      "26393       1\n",
      "3031        1\n",
      "26394       1\n",
      "26400       1\n",
      "3025        1\n",
      "26404       1\n",
      "26409       1\n",
      "26413       1\n",
      "26487       1\n",
      "26414       1\n",
      "26422       1\n",
      "26430       1\n",
      "26435       1\n",
      "26462       1\n",
      "26464       1\n",
      "26467       1\n",
      "26471       1\n",
      "26480       1\n",
      "26485       1\n",
      "163949      1\n",
      "Name: userId, dtype: int64\n",
      "On average, each movie is rated 11.030664019413193 times\n"
     ]
    }
   ],
   "source": [
    "# show how many users have rated a certain movie\n",
    "vector_sizes = data.groupby('movieId')['userId'].nunique().sort_values(ascending=False)\n",
    "print(vector_sizes)\n",
    "print('On average, each movie is rated {} times'.format(vector_sizes.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1263</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1293</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1343</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1405</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1953</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2105</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2150</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2193</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2294</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2455</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2968</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3671</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99974</th>\n",
       "      <td>671</td>\n",
       "      <td>4034</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99975</th>\n",
       "      <td>671</td>\n",
       "      <td>4306</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99976</th>\n",
       "      <td>671</td>\n",
       "      <td>4308</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99977</th>\n",
       "      <td>671</td>\n",
       "      <td>4880</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99978</th>\n",
       "      <td>671</td>\n",
       "      <td>4886</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99979</th>\n",
       "      <td>671</td>\n",
       "      <td>4896</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99980</th>\n",
       "      <td>671</td>\n",
       "      <td>4963</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99981</th>\n",
       "      <td>671</td>\n",
       "      <td>4973</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99982</th>\n",
       "      <td>671</td>\n",
       "      <td>4993</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99983</th>\n",
       "      <td>671</td>\n",
       "      <td>4995</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>671</td>\n",
       "      <td>5010</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>671</td>\n",
       "      <td>5218</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>671</td>\n",
       "      <td>5299</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>671</td>\n",
       "      <td>5349</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>671</td>\n",
       "      <td>5377</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>671</td>\n",
       "      <td>5445</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>671</td>\n",
       "      <td>5464</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <td>671</td>\n",
       "      <td>5669</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>671</td>\n",
       "      <td>5816</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>671</td>\n",
       "      <td>5902</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>671</td>\n",
       "      <td>5952</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>671</td>\n",
       "      <td>5989</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>671</td>\n",
       "      <td>5991</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>671</td>\n",
       "      <td>5995</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>671</td>\n",
       "      <td>6212</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>671</td>\n",
       "      <td>6268</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>671</td>\n",
       "      <td>6269</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>671</td>\n",
       "      <td>6365</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>671</td>\n",
       "      <td>6385</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>671</td>\n",
       "      <td>6565</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100004 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating\n",
       "0            1       31     2.5\n",
       "1            1     1029     3.0\n",
       "2            1     1061     3.0\n",
       "3            1     1129     2.0\n",
       "4            1     1172     4.0\n",
       "5            1     1263     2.0\n",
       "6            1     1287     2.0\n",
       "7            1     1293     2.0\n",
       "8            1     1339     3.5\n",
       "9            1     1343     2.0\n",
       "10           1     1371     2.5\n",
       "11           1     1405     1.0\n",
       "12           1     1953     4.0\n",
       "13           1     2105     4.0\n",
       "14           1     2150     3.0\n",
       "15           1     2193     2.0\n",
       "16           1     2294     2.0\n",
       "17           1     2455     2.5\n",
       "18           1     2968     1.0\n",
       "19           1     3671     3.0\n",
       "20           2       10     4.0\n",
       "21           2       17     5.0\n",
       "22           2       39     5.0\n",
       "23           2       47     4.0\n",
       "24           2       50     4.0\n",
       "25           2       52     3.0\n",
       "26           2       62     3.0\n",
       "27           2      110     4.0\n",
       "28           2      144     3.0\n",
       "29           2      150     5.0\n",
       "...        ...      ...     ...\n",
       "99974      671     4034     4.5\n",
       "99975      671     4306     5.0\n",
       "99976      671     4308     3.5\n",
       "99977      671     4880     4.0\n",
       "99978      671     4886     5.0\n",
       "99979      671     4896     5.0\n",
       "99980      671     4963     4.5\n",
       "99981      671     4973     4.5\n",
       "99982      671     4993     5.0\n",
       "99983      671     4995     4.0\n",
       "99984      671     5010     2.0\n",
       "99985      671     5218     2.0\n",
       "99986      671     5299     3.0\n",
       "99987      671     5349     4.0\n",
       "99988      671     5377     4.0\n",
       "99989      671     5445     4.5\n",
       "99990      671     5464     3.0\n",
       "99991      671     5669     4.0\n",
       "99992      671     5816     4.0\n",
       "99993      671     5902     3.5\n",
       "99994      671     5952     5.0\n",
       "99995      671     5989     4.0\n",
       "99996      671     5991     4.5\n",
       "99997      671     5995     4.0\n",
       "99998      671     6212     2.5\n",
       "99999      671     6268     2.5\n",
       "100000     671     6269     4.0\n",
       "100001     671     6365     4.0\n",
       "100002     671     6385     2.5\n",
       "100003     671     6565     3.5\n",
       "\n",
       "[100004 rows x 3 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show examples of the data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean centering\n",
    "Subtract mean of rating for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# find the mean of each user\n",
    "user_group = data.groupby(by='userId')\n",
    "user_means = user_group['rating'].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>meanCenteredRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1343</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1953</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2193</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2455</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3671</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.513158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.513158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.513158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.513158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.513158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.486842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.486842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.513158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.486842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.513158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99974</th>\n",
       "      <td>671</td>\n",
       "      <td>4034</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.582609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99975</th>\n",
       "      <td>671</td>\n",
       "      <td>4306</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99976</th>\n",
       "      <td>671</td>\n",
       "      <td>4308</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.417391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99977</th>\n",
       "      <td>671</td>\n",
       "      <td>4880</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99978</th>\n",
       "      <td>671</td>\n",
       "      <td>4886</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99979</th>\n",
       "      <td>671</td>\n",
       "      <td>4896</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99980</th>\n",
       "      <td>671</td>\n",
       "      <td>4963</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.582609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99981</th>\n",
       "      <td>671</td>\n",
       "      <td>4973</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.582609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99982</th>\n",
       "      <td>671</td>\n",
       "      <td>4993</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99983</th>\n",
       "      <td>671</td>\n",
       "      <td>4995</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>671</td>\n",
       "      <td>5010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.917391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>671</td>\n",
       "      <td>5218</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.917391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>671</td>\n",
       "      <td>5299</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.917391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>671</td>\n",
       "      <td>5349</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>671</td>\n",
       "      <td>5377</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>671</td>\n",
       "      <td>5445</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.582609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>671</td>\n",
       "      <td>5464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.917391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <td>671</td>\n",
       "      <td>5669</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>671</td>\n",
       "      <td>5816</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>671</td>\n",
       "      <td>5902</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.417391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>671</td>\n",
       "      <td>5952</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>671</td>\n",
       "      <td>5989</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>671</td>\n",
       "      <td>5991</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.582609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>671</td>\n",
       "      <td>5995</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>671</td>\n",
       "      <td>6212</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-1.417391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>671</td>\n",
       "      <td>6268</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-1.417391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>671</td>\n",
       "      <td>6269</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>671</td>\n",
       "      <td>6365</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>671</td>\n",
       "      <td>6385</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-1.417391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>671</td>\n",
       "      <td>6565</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.417391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100004 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating  meanCenteredRating\n",
       "0            1       31     2.5           -0.050000\n",
       "1            1     1029     3.0            0.450000\n",
       "2            1     1061     3.0            0.450000\n",
       "3            1     1129     2.0           -0.550000\n",
       "4            1     1172     4.0            1.450000\n",
       "5            1     1263     2.0           -0.550000\n",
       "6            1     1287     2.0           -0.550000\n",
       "7            1     1293     2.0           -0.550000\n",
       "8            1     1339     3.5            0.950000\n",
       "9            1     1343     2.0           -0.550000\n",
       "10           1     1371     2.5           -0.050000\n",
       "11           1     1405     1.0           -1.550000\n",
       "12           1     1953     4.0            1.450000\n",
       "13           1     2105     4.0            1.450000\n",
       "14           1     2150     3.0            0.450000\n",
       "15           1     2193     2.0           -0.550000\n",
       "16           1     2294     2.0           -0.550000\n",
       "17           1     2455     2.5           -0.050000\n",
       "18           1     2968     1.0           -1.550000\n",
       "19           1     3671     3.0            0.450000\n",
       "20           2       10     4.0            0.513158\n",
       "21           2       17     5.0            1.513158\n",
       "22           2       39     5.0            1.513158\n",
       "23           2       47     4.0            0.513158\n",
       "24           2       50     4.0            0.513158\n",
       "25           2       52     3.0           -0.486842\n",
       "26           2       62     3.0           -0.486842\n",
       "27           2      110     4.0            0.513158\n",
       "28           2      144     3.0           -0.486842\n",
       "29           2      150     5.0            1.513158\n",
       "...        ...      ...     ...                 ...\n",
       "99974      671     4034     4.5            0.582609\n",
       "99975      671     4306     5.0            1.082609\n",
       "99976      671     4308     3.5           -0.417391\n",
       "99977      671     4880     4.0            0.082609\n",
       "99978      671     4886     5.0            1.082609\n",
       "99979      671     4896     5.0            1.082609\n",
       "99980      671     4963     4.5            0.582609\n",
       "99981      671     4973     4.5            0.582609\n",
       "99982      671     4993     5.0            1.082609\n",
       "99983      671     4995     4.0            0.082609\n",
       "99984      671     5010     2.0           -1.917391\n",
       "99985      671     5218     2.0           -1.917391\n",
       "99986      671     5299     3.0           -0.917391\n",
       "99987      671     5349     4.0            0.082609\n",
       "99988      671     5377     4.0            0.082609\n",
       "99989      671     5445     4.5            0.582609\n",
       "99990      671     5464     3.0           -0.917391\n",
       "99991      671     5669     4.0            0.082609\n",
       "99992      671     5816     4.0            0.082609\n",
       "99993      671     5902     3.5           -0.417391\n",
       "99994      671     5952     5.0            1.082609\n",
       "99995      671     5989     4.0            0.082609\n",
       "99996      671     5991     4.5            0.582609\n",
       "99997      671     5995     4.0            0.082609\n",
       "99998      671     6212     2.5           -1.417391\n",
       "99999      671     6268     2.5           -1.417391\n",
       "100000     671     6269     4.0            0.082609\n",
       "100001     671     6365     4.0            0.082609\n",
       "100002     671     6385     2.5           -1.417391\n",
       "100003     671     6565     3.5           -0.417391\n",
       "\n",
       "[100004 rows x 4 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new column named \"meanCenteredRating\"\n",
    "\n",
    "# this function takes in ratings of one user and return mean_centered ratings of that user\n",
    "mean_centering = lambda ratings: ratings - ratings.mean()\n",
    "data['meanCenteredRating'] = user_group['rating'].transform(mean_centering)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.550000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.486842</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.568627</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.348039</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.910000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.261364</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.465909</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.866379</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.755556</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.695652</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.078947</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.754098</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.745283</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.950000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.621765</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.120690</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.743802</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.235294</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.534279</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.290816</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.506173</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.275000</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.632920</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.115385</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.468023</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.826087</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.280000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.863636</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.765084</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>3.916667</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>3.395833</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>3.743590</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>3.683333</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>4.130178</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>4.273333</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>3.628906</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>3.511111</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>3.310345</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>4.220974</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>4.068690</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>4.085714</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>4.523438</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>4.350000</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>3.387324</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>4.168478</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>3.833333</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>3.396552</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>3.730769</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>3.796724</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>3.285714</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2.950000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>3.647059</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>3.750000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>3.351351</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>3.806452</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>3.917391</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean  count\n",
       "userId                 \n",
       "1       2.550000     20\n",
       "2       3.486842     76\n",
       "3       3.568627     51\n",
       "4       4.348039    204\n",
       "5       3.910000    100\n",
       "6       3.261364     44\n",
       "7       3.465909     88\n",
       "8       3.866379    116\n",
       "9       3.755556     45\n",
       "10      3.695652     46\n",
       "11      4.078947     38\n",
       "12      2.754098     61\n",
       "13      3.745283     53\n",
       "14      2.950000     20\n",
       "15      2.621765   1700\n",
       "16      4.120690     29\n",
       "17      3.743802    363\n",
       "18      3.235294     51\n",
       "19      3.534279    423\n",
       "20      3.290816     98\n",
       "21      3.506173    162\n",
       "22      3.275000    220\n",
       "23      3.632920    726\n",
       "24      3.666667     21\n",
       "25      3.115385     26\n",
       "26      3.468023    172\n",
       "27      3.826087     23\n",
       "28      4.280000     50\n",
       "29      2.863636     22\n",
       "30      3.765084   1011\n",
       "...          ...    ...\n",
       "642     3.916667     36\n",
       "643     3.395833     24\n",
       "644     3.743590     39\n",
       "645     3.683333     30\n",
       "646     4.130178    169\n",
       "647     4.273333    150\n",
       "648     3.628906    256\n",
       "649     3.511111     90\n",
       "650     3.310345     29\n",
       "651     3.900000     20\n",
       "652     4.220974    267\n",
       "653     4.000000     51\n",
       "654     4.068690    626\n",
       "655     4.085714    105\n",
       "656     4.523438    128\n",
       "657     3.500000     20\n",
       "658     4.350000     60\n",
       "659     3.387324    142\n",
       "660     4.168478     92\n",
       "661     3.833333     33\n",
       "662     3.396552     58\n",
       "663     3.730769     26\n",
       "664     3.796724    519\n",
       "665     3.285714    434\n",
       "666     2.950000     40\n",
       "667     3.647059     68\n",
       "668     3.750000     20\n",
       "669     3.351351     37\n",
       "670     3.806452     31\n",
       "671     3.917391    115\n",
       "\n",
       "[671 rows x 2 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show user means\n",
    "user_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data\n",
    "Split the data into training set and test set. Prepare it as a user-item ratings matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80003, 4), (20001, 4))"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly split the data set\n",
    "test_size = 0.2\n",
    "data_train, data_test = train_test_split(data, test_size=test_size, random_state=42)\n",
    "\n",
    "# show shape of the data\n",
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 958 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# build userId to row mapping dictionary\n",
    "user2row = dict()\n",
    "row2user = dict()\n",
    "for i, user_id in enumerate(user_ids):\n",
    "    user2row[user_id] = i\n",
    "    row2user[i] = user_id\n",
    "\n",
    "# build movieId to column mapping dictionary\n",
    "movie2col = dict()\n",
    "col2movie = dict()\n",
    "for i, movie_id in enumerate(movie_ids):\n",
    "    movie2col[movie_id] = i\n",
    "    col2movie[i] = movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# turn ratings data in table format into a user-item rating matrix\n",
    "# the field will be filled with NaN if user didn't provide a rating\n",
    "def data_to_matrix(data):\n",
    "    mat = np.full((n_users, n_movies), np.nan, dtype=np.float32)\n",
    "    for idx, row in data.iterrows():\n",
    "        mat[user2row[row['userId']], movie2col[row['movieId']]] = row['meanCenteredRating']\n",
    "    return mat\n",
    "\n",
    "# prepare the data as a user-item rating matrix for the next step\n",
    "train_ratings = data_to_matrix(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute similarity matrix\n",
    "Build the item-item similarity matrix. This section takes most of the processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.98 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9066, 9066)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a blank similarity matrix containing zeros\n",
    "%time sim_matrix = np.zeros((n_movies, n_movies), dtype=np.float32)\n",
    "sim_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.,  4.]), array([-2.,  5.]))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove co-elements from 2 vectors if at least one of them is NaN\n",
    "def remove_nans(a, b):\n",
    "    # assuming that a and b are 1-d vectors, create a new axis for both of them\n",
    "    a = a[..., np.newaxis]\n",
    "    b = b[..., np.newaxis]\n",
    "    concat = np.concatenate([a, b], axis=1)\n",
    "    nonan = concat[~np.isnan(concat).any(axis=1)]\n",
    "    return nonan[:, 0], nonan[:, 1]\n",
    "\n",
    "# show examples of how to use remove_nans()\n",
    "a = np.array([-1,2     ,np.nan,4])\n",
    "b = np.array([-2,np.nan,3     ,5])\n",
    "remove_nans(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99083016804429913"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate a similarity value given 2 vectors\n",
    "# the output is a value between -1 and 1\n",
    "# min_co_elements is the number that determine whether to output NaN\n",
    "# or output the similarity value, if co-elements are too low, the similarity\n",
    "# will not be a good estimate, e.g. if there is only 1 co-element then the output\n",
    "# will only be either -1 or 1, that's sometimes not desirable, so a threshold should be given\n",
    "def calsim(item1, item2, min_co_elements=1):\n",
    "    item1, item2 = remove_nans(item1, item2)\n",
    "    if item1.size == 0 or item1.size < min_co_elements: # item1 and item2 must have the same size at this point\n",
    "        return np.nan\n",
    "#     print(item1.size)\n",
    "    dot = item1.dot(item2)\n",
    "    # find magnitude A.K.A. length of the vector by taking sqrt of the sum of squares of each element\n",
    "    norm1 = np.linalg.norm(item1)\n",
    "    norm2 = np.linalg.norm(item2)\n",
    "    return dot / (norm1 * norm2)\n",
    "\n",
    "# show example of how to use calsim()\n",
    "calsim(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 50/9066 (0.55 %) items calculated\n",
      "Progress: 100/9066 (1.10 %) items calculated\n",
      "Progress: 150/9066 (1.65 %) items calculated\n",
      "Progress: 200/9066 (2.21 %) items calculated\n",
      "Progress: 250/9066 (2.76 %) items calculated\n",
      "Progress: 300/9066 (3.31 %) items calculated\n",
      "Progress: 350/9066 (3.86 %) items calculated\n",
      "Progress: 400/9066 (4.41 %) items calculated\n",
      "Progress: 450/9066 (4.96 %) items calculated\n",
      "Progress: 500/9066 (5.52 %) items calculated\n",
      "Progress: 550/9066 (6.07 %) items calculated\n",
      "Progress: 600/9066 (6.62 %) items calculated\n",
      "Progress: 650/9066 (7.17 %) items calculated\n",
      "Progress: 700/9066 (7.72 %) items calculated\n",
      "Progress: 750/9066 (8.27 %) items calculated\n",
      "Progress: 800/9066 (8.82 %) items calculated\n",
      "Progress: 850/9066 (9.38 %) items calculated\n",
      "Progress: 900/9066 (9.93 %) items calculated\n",
      "Progress: 950/9066 (10.48 %) items calculated\n",
      "Progress: 1000/9066 (11.03 %) items calculated\n",
      "Progress: 1050/9066 (11.58 %) items calculated\n",
      "Progress: 1100/9066 (12.13 %) items calculated\n",
      "Progress: 1150/9066 (12.68 %) items calculated\n",
      "Progress: 1200/9066 (13.24 %) items calculated\n",
      "Progress: 1250/9066 (13.79 %) items calculated\n",
      "Progress: 1300/9066 (14.34 %) items calculated\n",
      "Progress: 1350/9066 (14.89 %) items calculated\n",
      "Progress: 1400/9066 (15.44 %) items calculated\n",
      "Progress: 1450/9066 (15.99 %) items calculated\n",
      "Progress: 1500/9066 (16.55 %) items calculated\n",
      "Progress: 1550/9066 (17.10 %) items calculated\n",
      "Progress: 1600/9066 (17.65 %) items calculated\n",
      "Progress: 1650/9066 (18.20 %) items calculated\n",
      "Progress: 1700/9066 (18.75 %) items calculated\n",
      "Progress: 1750/9066 (19.30 %) items calculated\n",
      "Progress: 1800/9066 (19.85 %) items calculated\n",
      "Progress: 1850/9066 (20.41 %) items calculated\n",
      "Progress: 1900/9066 (20.96 %) items calculated\n",
      "Progress: 1950/9066 (21.51 %) items calculated\n",
      "Progress: 2000/9066 (22.06 %) items calculated\n",
      "Progress: 2050/9066 (22.61 %) items calculated\n",
      "Progress: 2100/9066 (23.16 %) items calculated\n",
      "Progress: 2150/9066 (23.71 %) items calculated\n",
      "Progress: 2200/9066 (24.27 %) items calculated\n",
      "Progress: 2250/9066 (24.82 %) items calculated\n",
      "Progress: 2300/9066 (25.37 %) items calculated\n",
      "Progress: 2350/9066 (25.92 %) items calculated\n",
      "Progress: 2400/9066 (26.47 %) items calculated\n",
      "Progress: 2450/9066 (27.02 %) items calculated\n",
      "Progress: 2500/9066 (27.58 %) items calculated\n",
      "Progress: 2550/9066 (28.13 %) items calculated\n",
      "Progress: 2600/9066 (28.68 %) items calculated\n",
      "Progress: 2650/9066 (29.23 %) items calculated\n",
      "Progress: 2700/9066 (29.78 %) items calculated\n",
      "Progress: 2750/9066 (30.33 %) items calculated\n",
      "Progress: 2800/9066 (30.88 %) items calculated\n",
      "Progress: 2850/9066 (31.44 %) items calculated\n",
      "Progress: 2900/9066 (31.99 %) items calculated\n",
      "Progress: 2950/9066 (32.54 %) items calculated\n",
      "Progress: 3000/9066 (33.09 %) items calculated\n",
      "Progress: 3050/9066 (33.64 %) items calculated\n",
      "Progress: 3100/9066 (34.19 %) items calculated\n",
      "Progress: 3150/9066 (34.75 %) items calculated\n",
      "Progress: 3200/9066 (35.30 %) items calculated\n",
      "Progress: 3250/9066 (35.85 %) items calculated\n",
      "Progress: 3300/9066 (36.40 %) items calculated\n",
      "Progress: 3350/9066 (36.95 %) items calculated\n",
      "Progress: 3400/9066 (37.50 %) items calculated\n",
      "Progress: 3450/9066 (38.05 %) items calculated\n",
      "Progress: 3500/9066 (38.61 %) items calculated\n",
      "Progress: 3550/9066 (39.16 %) items calculated\n",
      "Progress: 3600/9066 (39.71 %) items calculated\n",
      "Progress: 3650/9066 (40.26 %) items calculated\n",
      "Progress: 3700/9066 (40.81 %) items calculated\n",
      "Progress: 3750/9066 (41.36 %) items calculated\n",
      "Progress: 3800/9066 (41.91 %) items calculated\n",
      "Progress: 3850/9066 (42.47 %) items calculated\n",
      "Progress: 3900/9066 (43.02 %) items calculated\n",
      "Progress: 3950/9066 (43.57 %) items calculated\n",
      "Progress: 4000/9066 (44.12 %) items calculated\n",
      "Progress: 4050/9066 (44.67 %) items calculated\n",
      "Progress: 4100/9066 (45.22 %) items calculated\n",
      "Progress: 4150/9066 (45.78 %) items calculated\n",
      "Progress: 4200/9066 (46.33 %) items calculated\n",
      "Progress: 4250/9066 (46.88 %) items calculated\n",
      "Progress: 4300/9066 (47.43 %) items calculated\n",
      "Progress: 4350/9066 (47.98 %) items calculated\n",
      "Progress: 4400/9066 (48.53 %) items calculated\n",
      "Progress: 4450/9066 (49.08 %) items calculated\n",
      "Progress: 4500/9066 (49.64 %) items calculated\n",
      "Progress: 4550/9066 (50.19 %) items calculated\n",
      "Progress: 4600/9066 (50.74 %) items calculated\n",
      "Progress: 4650/9066 (51.29 %) items calculated\n",
      "Progress: 4700/9066 (51.84 %) items calculated\n",
      "Progress: 4750/9066 (52.39 %) items calculated\n",
      "Progress: 4800/9066 (52.95 %) items calculated\n",
      "Progress: 4850/9066 (53.50 %) items calculated\n",
      "Progress: 4900/9066 (54.05 %) items calculated\n",
      "Progress: 4950/9066 (54.60 %) items calculated\n",
      "Progress: 5000/9066 (55.15 %) items calculated\n",
      "Progress: 5050/9066 (55.70 %) items calculated\n",
      "Progress: 5100/9066 (56.25 %) items calculated\n",
      "Progress: 5150/9066 (56.81 %) items calculated\n",
      "Progress: 5200/9066 (57.36 %) items calculated\n",
      "Progress: 5250/9066 (57.91 %) items calculated\n",
      "Progress: 5300/9066 (58.46 %) items calculated\n",
      "Progress: 5350/9066 (59.01 %) items calculated\n",
      "Progress: 5400/9066 (59.56 %) items calculated\n",
      "Progress: 5450/9066 (60.11 %) items calculated\n",
      "Progress: 5500/9066 (60.67 %) items calculated\n",
      "Progress: 5550/9066 (61.22 %) items calculated\n",
      "Progress: 5600/9066 (61.77 %) items calculated\n",
      "Progress: 5650/9066 (62.32 %) items calculated\n",
      "Progress: 5700/9066 (62.87 %) items calculated\n",
      "Progress: 5750/9066 (63.42 %) items calculated\n",
      "Progress: 5800/9066 (63.98 %) items calculated\n",
      "Progress: 5850/9066 (64.53 %) items calculated\n",
      "Progress: 5900/9066 (65.08 %) items calculated\n",
      "Progress: 5950/9066 (65.63 %) items calculated\n",
      "Progress: 6000/9066 (66.18 %) items calculated\n",
      "Progress: 6050/9066 (66.73 %) items calculated\n",
      "Progress: 6100/9066 (67.28 %) items calculated\n",
      "Progress: 6150/9066 (67.84 %) items calculated\n",
      "Progress: 6200/9066 (68.39 %) items calculated\n",
      "Progress: 6250/9066 (68.94 %) items calculated\n",
      "Progress: 6300/9066 (69.49 %) items calculated\n",
      "Progress: 6350/9066 (70.04 %) items calculated\n",
      "Progress: 6400/9066 (70.59 %) items calculated\n",
      "Progress: 6450/9066 (71.14 %) items calculated\n",
      "Progress: 6500/9066 (71.70 %) items calculated\n",
      "Progress: 6550/9066 (72.25 %) items calculated\n",
      "Progress: 6600/9066 (72.80 %) items calculated\n",
      "Progress: 6650/9066 (73.35 %) items calculated\n",
      "Progress: 6700/9066 (73.90 %) items calculated\n",
      "Progress: 6750/9066 (74.45 %) items calculated\n",
      "Progress: 6800/9066 (75.01 %) items calculated\n",
      "Progress: 6850/9066 (75.56 %) items calculated\n",
      "Progress: 6900/9066 (76.11 %) items calculated\n",
      "Progress: 6950/9066 (76.66 %) items calculated\n",
      "Progress: 7000/9066 (77.21 %) items calculated\n",
      "Progress: 7050/9066 (77.76 %) items calculated\n",
      "Progress: 7100/9066 (78.31 %) items calculated\n",
      "Progress: 7150/9066 (78.87 %) items calculated\n",
      "Progress: 7200/9066 (79.42 %) items calculated\n",
      "Progress: 7250/9066 (79.97 %) items calculated\n",
      "Progress: 7300/9066 (80.52 %) items calculated\n",
      "Progress: 7350/9066 (81.07 %) items calculated\n",
      "Progress: 7400/9066 (81.62 %) items calculated\n",
      "Progress: 7450/9066 (82.18 %) items calculated\n",
      "Progress: 7500/9066 (82.73 %) items calculated\n",
      "Progress: 7550/9066 (83.28 %) items calculated\n",
      "Progress: 7600/9066 (83.83 %) items calculated\n",
      "Progress: 7650/9066 (84.38 %) items calculated\n",
      "Progress: 7700/9066 (84.93 %) items calculated\n",
      "Progress: 7750/9066 (85.48 %) items calculated\n",
      "Progress: 7800/9066 (86.04 %) items calculated\n",
      "Progress: 7850/9066 (86.59 %) items calculated\n",
      "Progress: 7900/9066 (87.14 %) items calculated\n",
      "Progress: 7950/9066 (87.69 %) items calculated\n",
      "Progress: 8000/9066 (88.24 %) items calculated\n",
      "Progress: 8050/9066 (88.79 %) items calculated\n",
      "Progress: 8100/9066 (89.34 %) items calculated\n",
      "Progress: 8150/9066 (89.90 %) items calculated\n",
      "Progress: 8200/9066 (90.45 %) items calculated\n",
      "Progress: 8250/9066 (91.00 %) items calculated\n",
      "Progress: 8300/9066 (91.55 %) items calculated\n",
      "Progress: 8350/9066 (92.10 %) items calculated\n",
      "Progress: 8400/9066 (92.65 %) items calculated\n",
      "Progress: 8450/9066 (93.21 %) items calculated\n",
      "Progress: 8500/9066 (93.76 %) items calculated\n",
      "Progress: 8550/9066 (94.31 %) items calculated\n",
      "Progress: 8600/9066 (94.86 %) items calculated\n",
      "Progress: 8650/9066 (95.41 %) items calculated\n",
      "Progress: 8700/9066 (95.96 %) items calculated\n",
      "Progress: 8750/9066 (96.51 %) items calculated\n",
      "Progress: 8800/9066 (97.07 %) items calculated\n",
      "Progress: 8850/9066 (97.62 %) items calculated\n",
      "Progress: 8900/9066 (98.17 %) items calculated\n",
      "Progress: 8950/9066 (98.72 %) items calculated\n",
      "Progress: 9000/9066 (99.27 %) items calculated\n",
      "Progress: 9050/9066 (99.82 %) items calculated\n",
      "Progress: 9066/9066 (100.00 %) items calculated\n",
      "Wall time: 21min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# calculate all the similarities\n",
    "for item1 in range(n_movies):\n",
    "    item1vector = train_ratings[:, item1]\n",
    "    for item2 in range(item1, n_movies):\n",
    "        item2vector = train_ratings[:, item2]\n",
    "        sim = calsim(item1vector, item2vector, min_co_elements=2)\n",
    "        sim_matrix[item1, item2] = sim\n",
    "        sim_matrix[item2, item1] = sim\n",
    "    if (item1+1) % 50 == 0 or item1+1 == n_movies:\n",
    "        print(\"Progress: {}/{} ({:.2f} %) items calculated\".format(item1+1, n_movies, (item1+1)*100/n_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this sim matrix takes a lot of time to compute,\n",
    "# so saving it to the disk will help saving time in the future\n",
    "np.save('sim_matrix', sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractions of similarity matrix that are NaN: 0.936411215661\n"
     ]
    }
   ],
   "source": [
    "print('Fractions of similarity matrix that are NaN:', np.isnan(sim_matrix).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation\n",
    "Test recommendation using the item-item similarity matrix built previously.\n",
    "\n",
    "1. We first need to define a predict() function then use it repeatedly to predict rating of every movie of a given user.\n",
    "2. We then sort the predictions and show movies with top predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a predict function which receives row and column in the ratings matrix\n",
    "# then output a rating value (without mean addition), or np.nan if there are no co-items\n",
    "# user_item is a tuple (user_row, movie_column)\n",
    "# sim_threshold is the similarity threshold of each item,\n",
    "# if the item exceeds this value, it will be chosen for averaging the outcome\n",
    "def predict(ratings, user_item, sim_threshold, debug=True):\n",
    "    desired_user, desired_item = user_item\n",
    "    rating_sum = 0.\n",
    "    total_sim = 0.\n",
    "    for item in range(ratings.shape[1]):\n",
    "        s = sim_matrix[item, desired_item]\n",
    "        rating = ratings[desired_user, item]\n",
    "        if np.isnan(s) or s < sim_threshold or item == desired_item or np.isnan(rating):\n",
    "            continue\n",
    "        rating_sum += s * rating\n",
    "        total_sim += s\n",
    "        if debug:\n",
    "            print('sim and rating of item {}:'.format(item), s, rating)\n",
    "    return rating_sum / total_sim if total_sim else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the similarity threshold value, as the only hyperparameter available\n",
    "sim_threshold = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim and rating of item 906: 0.117642 -0.55\n",
      "sim and rating of item 1017: 0.0505805 -0.55\n",
      "sim and rating of item 1111: 0.815062 -0.05\n",
      "sim and rating of item 1140: 0.0289128 -1.55\n",
      "sim and rating of item 1665: 0.064384 1.45\n",
      "sim and rating of item 1708: 0.550293 0.45\n",
      "sim and rating of item 1815: 0.73969 -0.55\n",
      "sim and rating of item 2925: 0.0604668 0.45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.089294769241499483, -0.050000001)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(train_ratings, (0, 30), sim_threshold), train_ratings[0, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the movie names\n",
    "movie_file = \"ml-latest-small/movies.csv\"\n",
    "movie_df = pd.read_csv(movie_file, header=0)\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# desired_user is the user row that we want to recommend\n",
    "# return recommended item indices sorted by rating descendingly, and the associated score\n",
    "def recommend(ratings, desired_user, sim_threshold):\n",
    "    scores = []\n",
    "    for item in range(ratings.shape[1]):\n",
    "        score = ratings[desired_user, item]\n",
    "        if np.isnan(score):\n",
    "            score = predict(ratings, (desired_user, item), sim_threshold, debug=False)\n",
    "        else:\n",
    "            score = -np.infty # we don't want to recommend movies that user have rated\n",
    "        scores.append(score)\n",
    "    scores = np.array(scores)\n",
    "    scores_argsort = np.argsort(scores)[::-1]\n",
    "    scores_sort = np.sort(scores)[::-1]\n",
    "    \n",
    "    # numpy will put nan into the back of the array after sort\n",
    "    # when we reverse the array, nan will be at the front\n",
    "    # we want to move nan into the back again\n",
    "    # so we use a numpy trick which rolls the array value\n",
    "    # source: https://stackoverflow.com/a/35038821/2593810\n",
    "    no_of_nan = np.count_nonzero(np.isnan(scores))\n",
    "    scores_argsort = np.roll(scores_argsort, -no_of_nan)\n",
    "    scores_sort = np.roll(scores_sort, -no_of_nan)\n",
    "    return scores_argsort, scores_sort\n",
    "\n",
    "def recommend_msg(user_row, scores_argsort, scores_sort, how_many=10):\n",
    "    m = user_means.loc[row2user[user_row]]['mean']\n",
    "    print('User mean rating:', m)\n",
    "    msg = pd.DataFrame(columns=['movieId', 'title', 'genres', 'rating'])\n",
    "    for i in range(how_many):\n",
    "        col = scores_argsort[i]\n",
    "        movie_id = col2movie[col]\n",
    "        movie = movie_df.loc[movie_df['movieId'] == movie_id].iloc[0]\n",
    "        msg.loc[i+1] = [movie_id, movie['title'], movie['genres'], scores_sort[i] + m]\n",
    "    msg['movieId'] = msg['movieId'].astype(np.int32)\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user = 0 # the given user\n",
    "scores_argsort, scores_sort = recommend(train_ratings, user, sim_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4880, 1387, 5743, ..., 6780, 6782,  563], dtype=int64),\n",
       " array([ 1.45000012,  1.45000012,  1.45000011, ...,         nan,\n",
       "                nan,         nan]))"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_argsort, scores_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User mean rating: 2.55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6951</td>\n",
       "      <td>Cat in the Hat, The (2003)</td>\n",
       "      <td>Children|Comedy</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1769</td>\n",
       "      <td>Replacement Killers, The (1998)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26231</td>\n",
       "      <td>Performance (1970)</td>\n",
       "      <td>Crime|Drama|Thriller</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36276</td>\n",
       "      <td>Hidden (a.k.a. Cache) (Caché) (2005)</td>\n",
       "      <td>Drama|Mystery|Thriller</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4443</td>\n",
       "      <td>Outland (1981)</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>139757</td>\n",
       "      <td>Best of Enemies (2015)</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4570</td>\n",
       "      <td>Big Picture, The (1989)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3928</td>\n",
       "      <td>Abbott and Costello Meet Frankenstein (1948)</td>\n",
       "      <td>Comedy|Horror</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1943</td>\n",
       "      <td>Greatest Show on Earth, The (1952)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3181</td>\n",
       "      <td>Titus (1999)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movieId                                         title  \\\n",
       "1      6951                    Cat in the Hat, The (2003)   \n",
       "2      1769               Replacement Killers, The (1998)   \n",
       "3     26231                            Performance (1970)   \n",
       "4     36276          Hidden (a.k.a. Cache) (Caché) (2005)   \n",
       "5      4443                                Outland (1981)   \n",
       "6    139757                        Best of Enemies (2015)   \n",
       "7      4570                       Big Picture, The (1989)   \n",
       "8      3928  Abbott and Costello Meet Frankenstein (1948)   \n",
       "9      1943            Greatest Show on Earth, The (1952)   \n",
       "10     3181                                  Titus (1999)   \n",
       "\n",
       "                    genres  rating  \n",
       "1          Children|Comedy     4.0  \n",
       "2    Action|Crime|Thriller     4.0  \n",
       "3     Crime|Drama|Thriller     4.0  \n",
       "4   Drama|Mystery|Thriller     4.0  \n",
       "5   Action|Sci-Fi|Thriller     4.0  \n",
       "6              Documentary     4.0  \n",
       "7             Comedy|Drama     4.0  \n",
       "8            Comedy|Horror     4.0  \n",
       "9                    Drama     4.0  \n",
       "10                   Drama     4.0  "
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_msg(user, scores_argsort, scores_sort, how_many=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the error on the test set. The error metric chosen in our work is **MAE**.\n",
    "1. We need to predict mean centered ratings of every (user,movie) pair in the test data\n",
    "2. Take the difference between the true ratings and the predicted ratings\n",
    "3. Take the absolute\n",
    "4. Take the mean\n",
    "\n",
    "And that's how the error is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>meanCenteredRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19090</th>\n",
       "      <td>128</td>\n",
       "      <td>1028</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.139319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99678</th>\n",
       "      <td>665</td>\n",
       "      <td>4736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18455</th>\n",
       "      <td>120</td>\n",
       "      <td>4002</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.485507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35755</th>\n",
       "      <td>257</td>\n",
       "      <td>1274</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.393204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66536</th>\n",
       "      <td>468</td>\n",
       "      <td>6440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.034082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating  meanCenteredRating\n",
       "19090     128     1028     5.0            1.139319\n",
       "99678     665     4736     1.0           -2.285714\n",
       "18455     120     4002     3.0           -0.485507\n",
       "35755     257     1274     4.0            0.393204\n",
       "66536     468     6440     4.0            1.034082"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, let's take a look at some of the test data\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict ratings for the given data table\n",
    "def predict_table(data_test, sim_threshold, show_progress=True):\n",
    "    n_test = data_test.shape[0]\n",
    "    predictions = np.empty((n_test,))\n",
    "    i = 0\n",
    "    for idx, row in data_test.iterrows():\n",
    "        pred = predict(train_ratings, (user2row[row['userId']], movie2col[row['movieId']]), sim_threshold, debug=False)\n",
    "        predictions[i] = pred\n",
    "        if show_progress and ((i+1) % 100 == 0 or i+1 == n_test):\n",
    "            print(\"Progress: {}/{} ({:.2f} %) ratings predicted\".format(i+1, n_test, (i+1)*100/n_test))\n",
    "        i += 1\n",
    "    if show_progress:\n",
    "        print(\"Progress: {}/{} ({:.2f} %) ratings predicted\".format(i+1, n_test, (i+1)*100/n_test))\n",
    "    return predictions\n",
    "\n",
    "def eval_error(data_test, predictions):\n",
    "    return np.abs(data_test['meanCenteredRating'] - predictions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100/20001 (0.50 %) ratings predicted\n",
      "Progress: 200/20001 (1.00 %) ratings predicted\n",
      "Progress: 300/20001 (1.50 %) ratings predicted\n",
      "Progress: 400/20001 (2.00 %) ratings predicted\n",
      "Progress: 500/20001 (2.50 %) ratings predicted\n",
      "Progress: 600/20001 (3.00 %) ratings predicted\n",
      "Progress: 700/20001 (3.50 %) ratings predicted\n",
      "Progress: 800/20001 (4.00 %) ratings predicted\n",
      "Progress: 900/20001 (4.50 %) ratings predicted\n",
      "Progress: 1000/20001 (5.00 %) ratings predicted\n",
      "Progress: 1100/20001 (5.50 %) ratings predicted\n",
      "Progress: 1200/20001 (6.00 %) ratings predicted\n",
      "Progress: 1300/20001 (6.50 %) ratings predicted\n",
      "Progress: 1400/20001 (7.00 %) ratings predicted\n",
      "Progress: 1500/20001 (7.50 %) ratings predicted\n",
      "Progress: 1600/20001 (8.00 %) ratings predicted\n",
      "Progress: 1700/20001 (8.50 %) ratings predicted\n",
      "Progress: 1800/20001 (9.00 %) ratings predicted\n",
      "Progress: 1900/20001 (9.50 %) ratings predicted\n",
      "Progress: 2000/20001 (10.00 %) ratings predicted\n",
      "Progress: 2100/20001 (10.50 %) ratings predicted\n",
      "Progress: 2200/20001 (11.00 %) ratings predicted\n",
      "Progress: 2300/20001 (11.50 %) ratings predicted\n",
      "Progress: 2400/20001 (12.00 %) ratings predicted\n",
      "Progress: 2500/20001 (12.50 %) ratings predicted\n",
      "Progress: 2600/20001 (13.00 %) ratings predicted\n",
      "Progress: 2700/20001 (13.50 %) ratings predicted\n",
      "Progress: 2800/20001 (14.00 %) ratings predicted\n",
      "Progress: 2900/20001 (14.50 %) ratings predicted\n",
      "Progress: 3000/20001 (15.00 %) ratings predicted\n",
      "Progress: 3100/20001 (15.50 %) ratings predicted\n",
      "Progress: 3200/20001 (16.00 %) ratings predicted\n",
      "Progress: 3300/20001 (16.50 %) ratings predicted\n",
      "Progress: 3400/20001 (17.00 %) ratings predicted\n",
      "Progress: 3500/20001 (17.50 %) ratings predicted\n",
      "Progress: 3600/20001 (18.00 %) ratings predicted\n",
      "Progress: 3700/20001 (18.50 %) ratings predicted\n",
      "Progress: 3800/20001 (19.00 %) ratings predicted\n",
      "Progress: 3900/20001 (19.50 %) ratings predicted\n",
      "Progress: 4000/20001 (20.00 %) ratings predicted\n",
      "Progress: 4100/20001 (20.50 %) ratings predicted\n",
      "Progress: 4200/20001 (21.00 %) ratings predicted\n",
      "Progress: 4300/20001 (21.50 %) ratings predicted\n",
      "Progress: 4400/20001 (22.00 %) ratings predicted\n",
      "Progress: 4500/20001 (22.50 %) ratings predicted\n",
      "Progress: 4600/20001 (23.00 %) ratings predicted\n",
      "Progress: 4700/20001 (23.50 %) ratings predicted\n",
      "Progress: 4800/20001 (24.00 %) ratings predicted\n",
      "Progress: 4900/20001 (24.50 %) ratings predicted\n",
      "Progress: 5000/20001 (25.00 %) ratings predicted\n",
      "Progress: 5100/20001 (25.50 %) ratings predicted\n",
      "Progress: 5200/20001 (26.00 %) ratings predicted\n",
      "Progress: 5300/20001 (26.50 %) ratings predicted\n",
      "Progress: 5400/20001 (27.00 %) ratings predicted\n",
      "Progress: 5500/20001 (27.50 %) ratings predicted\n",
      "Progress: 5600/20001 (28.00 %) ratings predicted\n",
      "Progress: 5700/20001 (28.50 %) ratings predicted\n",
      "Progress: 5800/20001 (29.00 %) ratings predicted\n",
      "Progress: 5900/20001 (29.50 %) ratings predicted\n",
      "Progress: 6000/20001 (30.00 %) ratings predicted\n",
      "Progress: 6100/20001 (30.50 %) ratings predicted\n",
      "Progress: 6200/20001 (31.00 %) ratings predicted\n",
      "Progress: 6300/20001 (31.50 %) ratings predicted\n",
      "Progress: 6400/20001 (32.00 %) ratings predicted\n",
      "Progress: 6500/20001 (32.50 %) ratings predicted\n",
      "Progress: 6600/20001 (33.00 %) ratings predicted\n",
      "Progress: 6700/20001 (33.50 %) ratings predicted\n",
      "Progress: 6800/20001 (34.00 %) ratings predicted\n",
      "Progress: 6900/20001 (34.50 %) ratings predicted\n",
      "Progress: 7000/20001 (35.00 %) ratings predicted\n",
      "Progress: 7100/20001 (35.50 %) ratings predicted\n",
      "Progress: 7200/20001 (36.00 %) ratings predicted\n",
      "Progress: 7300/20001 (36.50 %) ratings predicted\n",
      "Progress: 7400/20001 (37.00 %) ratings predicted\n",
      "Progress: 7500/20001 (37.50 %) ratings predicted\n",
      "Progress: 7600/20001 (38.00 %) ratings predicted\n",
      "Progress: 7700/20001 (38.50 %) ratings predicted\n",
      "Progress: 7800/20001 (39.00 %) ratings predicted\n",
      "Progress: 7900/20001 (39.50 %) ratings predicted\n",
      "Progress: 8000/20001 (40.00 %) ratings predicted\n",
      "Progress: 8100/20001 (40.50 %) ratings predicted\n",
      "Progress: 8200/20001 (41.00 %) ratings predicted\n",
      "Progress: 8300/20001 (41.50 %) ratings predicted\n",
      "Progress: 8400/20001 (42.00 %) ratings predicted\n",
      "Progress: 8500/20001 (42.50 %) ratings predicted\n",
      "Progress: 8600/20001 (43.00 %) ratings predicted\n",
      "Progress: 8700/20001 (43.50 %) ratings predicted\n",
      "Progress: 8800/20001 (44.00 %) ratings predicted\n",
      "Progress: 8900/20001 (44.50 %) ratings predicted\n",
      "Progress: 9000/20001 (45.00 %) ratings predicted\n",
      "Progress: 9100/20001 (45.50 %) ratings predicted\n",
      "Progress: 9200/20001 (46.00 %) ratings predicted\n",
      "Progress: 9300/20001 (46.50 %) ratings predicted\n",
      "Progress: 9400/20001 (47.00 %) ratings predicted\n",
      "Progress: 9500/20001 (47.50 %) ratings predicted\n",
      "Progress: 9600/20001 (48.00 %) ratings predicted\n",
      "Progress: 9700/20001 (48.50 %) ratings predicted\n",
      "Progress: 9800/20001 (49.00 %) ratings predicted\n",
      "Progress: 9900/20001 (49.50 %) ratings predicted\n",
      "Progress: 10000/20001 (50.00 %) ratings predicted\n",
      "Progress: 10100/20001 (50.50 %) ratings predicted\n",
      "Progress: 10200/20001 (51.00 %) ratings predicted\n",
      "Progress: 10300/20001 (51.50 %) ratings predicted\n",
      "Progress: 10400/20001 (52.00 %) ratings predicted\n",
      "Progress: 10500/20001 (52.50 %) ratings predicted\n",
      "Progress: 10600/20001 (53.00 %) ratings predicted\n",
      "Progress: 10700/20001 (53.50 %) ratings predicted\n",
      "Progress: 10800/20001 (54.00 %) ratings predicted\n",
      "Progress: 10900/20001 (54.50 %) ratings predicted\n",
      "Progress: 11000/20001 (55.00 %) ratings predicted\n",
      "Progress: 11100/20001 (55.50 %) ratings predicted\n",
      "Progress: 11200/20001 (56.00 %) ratings predicted\n",
      "Progress: 11300/20001 (56.50 %) ratings predicted\n",
      "Progress: 11400/20001 (57.00 %) ratings predicted\n",
      "Progress: 11500/20001 (57.50 %) ratings predicted\n",
      "Progress: 11600/20001 (58.00 %) ratings predicted\n",
      "Progress: 11700/20001 (58.50 %) ratings predicted\n",
      "Progress: 11800/20001 (59.00 %) ratings predicted\n",
      "Progress: 11900/20001 (59.50 %) ratings predicted\n",
      "Progress: 12000/20001 (60.00 %) ratings predicted\n",
      "Progress: 12100/20001 (60.50 %) ratings predicted\n",
      "Progress: 12200/20001 (61.00 %) ratings predicted\n",
      "Progress: 12300/20001 (61.50 %) ratings predicted\n",
      "Progress: 12400/20001 (62.00 %) ratings predicted\n",
      "Progress: 12500/20001 (62.50 %) ratings predicted\n",
      "Progress: 12600/20001 (63.00 %) ratings predicted\n",
      "Progress: 12700/20001 (63.50 %) ratings predicted\n",
      "Progress: 12800/20001 (64.00 %) ratings predicted\n",
      "Progress: 12900/20001 (64.50 %) ratings predicted\n",
      "Progress: 13000/20001 (65.00 %) ratings predicted\n",
      "Progress: 13100/20001 (65.50 %) ratings predicted\n",
      "Progress: 13200/20001 (66.00 %) ratings predicted\n",
      "Progress: 13300/20001 (66.50 %) ratings predicted\n",
      "Progress: 13400/20001 (67.00 %) ratings predicted\n",
      "Progress: 13500/20001 (67.50 %) ratings predicted\n",
      "Progress: 13600/20001 (68.00 %) ratings predicted\n",
      "Progress: 13700/20001 (68.50 %) ratings predicted\n",
      "Progress: 13800/20001 (69.00 %) ratings predicted\n",
      "Progress: 13900/20001 (69.50 %) ratings predicted\n",
      "Progress: 14000/20001 (70.00 %) ratings predicted\n",
      "Progress: 14100/20001 (70.50 %) ratings predicted\n",
      "Progress: 14200/20001 (71.00 %) ratings predicted\n",
      "Progress: 14300/20001 (71.50 %) ratings predicted\n",
      "Progress: 14400/20001 (72.00 %) ratings predicted\n",
      "Progress: 14500/20001 (72.50 %) ratings predicted\n",
      "Progress: 14600/20001 (73.00 %) ratings predicted\n",
      "Progress: 14700/20001 (73.50 %) ratings predicted\n",
      "Progress: 14800/20001 (74.00 %) ratings predicted\n",
      "Progress: 14900/20001 (74.50 %) ratings predicted\n",
      "Progress: 15000/20001 (75.00 %) ratings predicted\n",
      "Progress: 15100/20001 (75.50 %) ratings predicted\n",
      "Progress: 15200/20001 (76.00 %) ratings predicted\n",
      "Progress: 15300/20001 (76.50 %) ratings predicted\n",
      "Progress: 15400/20001 (77.00 %) ratings predicted\n",
      "Progress: 15500/20001 (77.50 %) ratings predicted\n",
      "Progress: 15600/20001 (78.00 %) ratings predicted\n",
      "Progress: 15700/20001 (78.50 %) ratings predicted\n",
      "Progress: 15800/20001 (79.00 %) ratings predicted\n",
      "Progress: 15900/20001 (79.50 %) ratings predicted\n",
      "Progress: 16000/20001 (80.00 %) ratings predicted\n",
      "Progress: 16100/20001 (80.50 %) ratings predicted\n",
      "Progress: 16200/20001 (81.00 %) ratings predicted\n",
      "Progress: 16300/20001 (81.50 %) ratings predicted\n",
      "Progress: 16400/20001 (82.00 %) ratings predicted\n",
      "Progress: 16500/20001 (82.50 %) ratings predicted\n",
      "Progress: 16600/20001 (83.00 %) ratings predicted\n",
      "Progress: 16700/20001 (83.50 %) ratings predicted\n",
      "Progress: 16800/20001 (84.00 %) ratings predicted\n",
      "Progress: 16900/20001 (84.50 %) ratings predicted\n",
      "Progress: 17000/20001 (85.00 %) ratings predicted\n",
      "Progress: 17100/20001 (85.50 %) ratings predicted\n",
      "Progress: 17200/20001 (86.00 %) ratings predicted\n",
      "Progress: 17300/20001 (86.50 %) ratings predicted\n",
      "Progress: 17400/20001 (87.00 %) ratings predicted\n",
      "Progress: 17500/20001 (87.50 %) ratings predicted\n",
      "Progress: 17600/20001 (88.00 %) ratings predicted\n",
      "Progress: 17700/20001 (88.50 %) ratings predicted\n",
      "Progress: 17800/20001 (89.00 %) ratings predicted\n",
      "Progress: 17900/20001 (89.50 %) ratings predicted\n",
      "Progress: 18000/20001 (90.00 %) ratings predicted\n",
      "Progress: 18100/20001 (90.50 %) ratings predicted\n",
      "Progress: 18200/20001 (91.00 %) ratings predicted\n",
      "Progress: 18300/20001 (91.50 %) ratings predicted\n",
      "Progress: 18400/20001 (92.00 %) ratings predicted\n",
      "Progress: 18500/20001 (92.50 %) ratings predicted\n",
      "Progress: 18600/20001 (93.00 %) ratings predicted\n",
      "Progress: 18700/20001 (93.50 %) ratings predicted\n",
      "Progress: 18800/20001 (94.00 %) ratings predicted\n",
      "Progress: 18900/20001 (94.50 %) ratings predicted\n",
      "Progress: 19000/20001 (95.00 %) ratings predicted\n",
      "Progress: 19100/20001 (95.50 %) ratings predicted\n",
      "Progress: 19200/20001 (96.00 %) ratings predicted\n",
      "Progress: 19300/20001 (96.50 %) ratings predicted\n",
      "Progress: 19400/20001 (97.00 %) ratings predicted\n",
      "Progress: 19500/20001 (97.50 %) ratings predicted\n",
      "Progress: 19600/20001 (98.00 %) ratings predicted\n",
      "Progress: 19700/20001 (98.50 %) ratings predicted\n",
      "Progress: 19800/20001 (99.00 %) ratings predicted\n",
      "Progress: 19900/20001 (99.50 %) ratings predicted\n",
      "Progress: 20000/20001 (100.00 %) ratings predicted\n",
      "Progress: 20001/20001 (100.00 %) ratings predicted\n",
      "Progress: 20002/20001 (100.00 %) ratings predicted\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predicting ratings for every (user,movie) pair in the test data\n",
    "predictions = predict_table(data_test, sim_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>meanCenteredRating</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19090</th>\n",
       "      <td>128</td>\n",
       "      <td>1028</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.139319</td>\n",
       "      <td>-0.075033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99678</th>\n",
       "      <td>665</td>\n",
       "      <td>4736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.285714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18455</th>\n",
       "      <td>120</td>\n",
       "      <td>4002</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.485507</td>\n",
       "      <td>0.090853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35755</th>\n",
       "      <td>257</td>\n",
       "      <td>1274</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.393204</td>\n",
       "      <td>0.329624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66536</th>\n",
       "      <td>468</td>\n",
       "      <td>6440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.034082</td>\n",
       "      <td>0.169497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating  meanCenteredRating  prediction\n",
       "19090     128     1028     5.0            1.139319   -0.075033\n",
       "99678     665     4736     1.0           -2.285714         NaN\n",
       "18455     120     4002     3.0           -0.485507    0.090853\n",
       "35755     257     1274     4.0            0.393204    0.329624\n",
       "66536     468     6440     4.0            1.034082    0.169497"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['prediction'] = predictions\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>meanCenteredRating</th>\n",
       "      <th>prediction</th>\n",
       "      <th>abs_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19090</th>\n",
       "      <td>128</td>\n",
       "      <td>1028</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.139319</td>\n",
       "      <td>-0.075033</td>\n",
       "      <td>1.214352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99678</th>\n",
       "      <td>665</td>\n",
       "      <td>4736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.285714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18455</th>\n",
       "      <td>120</td>\n",
       "      <td>4002</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.485507</td>\n",
       "      <td>0.090853</td>\n",
       "      <td>0.576360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35755</th>\n",
       "      <td>257</td>\n",
       "      <td>1274</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.393204</td>\n",
       "      <td>0.329624</td>\n",
       "      <td>0.063580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66536</th>\n",
       "      <td>468</td>\n",
       "      <td>6440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.034082</td>\n",
       "      <td>0.169497</td>\n",
       "      <td>0.864585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating  meanCenteredRating  prediction  abs_error\n",
       "19090     128     1028     5.0            1.139319   -0.075033   1.214352\n",
       "99678     665     4736     1.0           -2.285714         NaN        NaN\n",
       "18455     120     4002     3.0           -0.485507    0.090853   0.576360\n",
       "35755     257     1274     4.0            0.393204    0.329624   0.063580\n",
       "66536     468     6440     4.0            1.034082    0.169497   0.864585"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['abs_error'] = np.abs(data_test['meanCenteredRating'] - data_test['prediction'])\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6850314415989894"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean absolute error\n",
    "mae = data_test['abs_error'].mean()\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Optimization\n",
    "Find the best set of hyperparameters that yields the lowest error on the test set.\n",
    "In this work, we use **sim_threshold (similarity threshold)** as the only hyperparameter of the system.\n",
    "\n",
    "We can find the best **sim_threshold** by iteratively\n",
    "1. varying its value\n",
    "2. predict outcome on the test set\n",
    "3. evaluate the error\n",
    "4. if the error is less than the least error found so far, save current **sim_threshold** as the best candidate\n",
    "\n",
    "Repeat this cycle until enough satisfaction is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.  , -0.75, -0.5 , -0.25,  0.  ,  0.25,  0.5 ,  0.75])"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a set of avaialble similarity thresholds\n",
    "candidate_sim_thresholds = np.linspace(-1, 0.75, num=8)\n",
    "candidate_sim_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current similarity threshold: -1.0\n",
      "Error: 5.3854645633058125\n",
      "Current similarity threshold: -0.75\n",
      "Error: 4.346330162855901\n",
      "Current similarity threshold: -0.5\n",
      "Error: 1.2072844441814714\n",
      "Current similarity threshold: -0.25\n",
      "Error: 0.7409731445041101\n",
      "Current similarity threshold: 0.0\n",
      "Error: 0.6850314415989894\n",
      "Current similarity threshold: 0.25\n",
      "Error: 0.6855344082989672\n",
      "Current similarity threshold: 0.5\n",
      "Error: 0.7016853455082093\n",
      "Current similarity threshold: 0.75\n",
      "Error: 0.7372740982861828\n",
      "Wall time: 40min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "errors = np.empty_like(candidate_sim_thresholds, dtype=np.float32)\n",
    "for i, sim_threshold in enumerate(candidate_sim_thresholds):\n",
    "    print('Current similarity threshold:', sim_threshold)\n",
    "    predictions = predict_table(data_test, sim_threshold, show_progress=False)\n",
    "    error = eval_error(data_test, predictions)\n",
    "    print('Error:', error)\n",
    "    errors[i] = error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.38546467,  4.34633017,  1.20728445,  0.74097311,  0.68503141,\n",
       "        0.68553442,  0.70168537,  0.73727411], dtype=float32)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_error_idx = np.argmin(errors)\n",
    "best_error = errors[best_error_idx]\n",
    "best_sim_threshold = candidate_sim_thresholds[best_error_idx]\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal similarity threshold: 0.0\n",
      "Optimal error: 0.685031\n"
     ]
    }
   ],
   "source": [
    "print('Optimal similarity threshold:', best_sim_threshold)\n",
    "print('Optimal error:', best_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the error as a function of **sim_threshold**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAGHCAYAAAAKvNDsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nglL8H0ygxfMuHTmrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x215acf626d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(candidate_sim_thresholds, errors, 'r*--')\n",
    "plt.xlabel('similarity threshold')\n",
    "plt.ylabel('MAE (mean absolute error)')\n",
    "plt.grid()\n",
    "plt.title('error as a function of sim_threshold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Inference on the Real World\n",
    "This is the last step, all we have done to this point is now on production.\n",
    "\n",
    "**Our task:** Given a user, recommend some movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose a user_id from the data\n",
    "user_id = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_row = user2row[user_id]\n",
    "scores_argsort, scores_sort = recommend(train_ratings, user_row, best_sim_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User mean rating: 2.98192771084\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6211</td>\n",
       "      <td>Ten (2002)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1596</td>\n",
       "      <td>Career Girls (1997)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50685</td>\n",
       "      <td>Waitress (2007)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>4.722129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105246</td>\n",
       "      <td>Mood Indigo (L'écume des jours) (2013)</td>\n",
       "      <td>Drama|Fantasy</td>\n",
       "      <td>4.522029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8014</td>\n",
       "      <td>Spring, Summer, Fall, Winter... and Spring (Bo...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>4.507308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5646</td>\n",
       "      <td>Valmont (1989)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37853</td>\n",
       "      <td>Into the Blue (2005)</td>\n",
       "      <td>Action|Adventure|Crime|Thriller</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31408</td>\n",
       "      <td>Summer Storm (Sommersturm) (2004)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70862</td>\n",
       "      <td>It Might Get Loud (2008)</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25868</td>\n",
       "      <td>Ball of Fire (1941)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movieId                                              title  \\\n",
       "1      6211                                         Ten (2002)   \n",
       "2      1596                                Career Girls (1997)   \n",
       "3     50685                                    Waitress (2007)   \n",
       "4    105246             Mood Indigo (L'écume des jours) (2013)   \n",
       "5      8014  Spring, Summer, Fall, Winter... and Spring (Bo...   \n",
       "6      5646                                     Valmont (1989)   \n",
       "7     37853                               Into the Blue (2005)   \n",
       "8     31408                  Summer Storm (Sommersturm) (2004)   \n",
       "9     70862                           It Might Get Loud (2008)   \n",
       "10    25868                                Ball of Fire (1941)   \n",
       "\n",
       "                             genres    rating  \n",
       "1                             Drama  5.000000  \n",
       "2                             Drama  5.000000  \n",
       "3              Comedy|Drama|Romance  4.722129  \n",
       "4                     Drama|Fantasy  4.522029  \n",
       "5                             Drama  4.507308  \n",
       "6                     Drama|Romance  4.500000  \n",
       "7   Action|Adventure|Crime|Thriller  4.500000  \n",
       "8                     Drama|Romance  4.500000  \n",
       "9                       Documentary  4.500000  \n",
       "10                   Comedy|Romance  4.500000  "
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_msg(user_row, scores_argsort, scores_sort, how_many=10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
